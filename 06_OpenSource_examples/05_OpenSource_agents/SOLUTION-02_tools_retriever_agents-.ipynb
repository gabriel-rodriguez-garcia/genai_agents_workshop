{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a5ab2f-d044-4956-b75b-7408d9c3e323",
   "metadata": {},
   "source": [
    "# Leveraging Agents with LangChain\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio. You can also run on a local setup, as long as you have the right IAM credentials to invoke the Claude model via Bedrock*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeedd9f-f0a3-4f8e-934d-22f6f7a89de5",
   "metadata": {},
   "source": [
    "### Building  - Key Elements\n",
    "\n",
    "The first process in a building a contextual-aware chatbot is to identify the tools which can be called by the LLM's. \n",
    "\n",
    "Second process is the user request orchestration , interaction,  invoking and returing the results\n",
    "\n",
    "### Architecture [Weather lookup]\n",
    "We Search and look for the Latitude and Longitude and then invoke the weather app to get predictions\n",
    "\n",
    "![Amazon Bedrock - Agents Interface](./images/weather.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5edcc6",
   "metadata": {},
   "source": [
    "#### Please un comment and install the libraries below if you do not have these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43a8c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.17\n",
      "  Using cached langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.17) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.17) (2.0.29)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.1.17)\n",
      "  Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.1.17)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.17)\n",
      "  Using cached dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.17) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.36 (from langchain==0.1.17)\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.48 (from langchain==0.1.17)\n",
      "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.17)\n",
      "  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.17)\n",
      "  Using cached langsmith-0.1.60-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.17) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.17) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.17) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.17) (8.2.3)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.17)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (3.21.1)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.17)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.17) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain==0.1.17) (23.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.17)\n",
      "  Using cached orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.17) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.17) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.17) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.17) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.17) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.17) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.17) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.17) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.17) (1.0.0)\n",
      "Using cached langchain-0.1.17-py3-none-any.whl (867 kB)\n",
      "Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "Using cached langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "Using cached langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Using cached langsmith-0.1.60-py3-none-any.whl (121 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Using cached orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Installing collected packages: typing-inspect, orjson, multidict, frozenlist, async-timeout, yarl, dataclasses-json, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.6 frozenlist-1.4.1 langchain-0.1.17 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.60 multidict-6.0.5 orjson-3.10.3 typing-inspect-0.9.0 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting faiss-cpu==1.8.0\n",
      "  Using cached faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from faiss-cpu==1.8.0) (1.26.4)\n",
      "Using cached faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pypdf\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.10/site-packages (from pypdf) (4.11.0)\n",
      "Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain_aws\n",
      "  Using cached langchain_aws-0.1.4-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: boto3<1.35.0,>=1.34.51 in /opt/conda/lib/python3.10/site-packages (from langchain_aws) (1.34.84)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.45 in /opt/conda/lib/python3.10/site-packages (from langchain_aws) (0.1.52)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_aws) (1.26.4)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.84 in /opt/conda/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.51->langchain_aws) (1.34.84)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.51->langchain_aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.51->langchain_aws) (0.10.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain_aws) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain_aws) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain_aws) (0.1.60)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain_aws) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain_aws) (2.7.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.45->langchain_aws) (8.2.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.84->boto3<1.35.0,>=1.34.51->langchain_aws) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.84->boto3<1.35.0,>=1.34.51->langchain_aws) (2.2.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.45->langchain_aws) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_aws) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_aws) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.45->langchain_aws) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.45->langchain_aws) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.45->langchain_aws) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.84->boto3<1.35.0,>=1.34.51->langchain_aws) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_aws) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_aws) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_aws) (2024.2.2)\n",
      "Using cached langchain_aws-0.1.4-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: langchain_aws\n",
      "Successfully installed langchain_aws-0.1.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.34.84)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.84 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.34.84)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.84->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.84->boto3) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.84->boto3) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain-anthropic\n",
      "  Using cached langchain_anthropic-0.1.13-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting anthropic<1,>=0.26.0 (from langchain-anthropic)\n",
      "  Using cached anthropic-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from langchain-anthropic) (0.7.1)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.43 in /opt/conda/lib/python3.10/site-packages (from langchain-anthropic) (0.1.52)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<1,>=0.26.0->langchain-anthropic) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<1,>=0.26.0->langchain-anthropic) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<1,>=0.26.0->langchain-anthropic) (0.27.0)\n",
      "Collecting jiter<1,>=0.1.0 (from anthropic<1,>=0.26.0->langchain-anthropic)\n",
      "  Using cached jiter-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<1,>=0.26.0->langchain-anthropic) (2.7.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from anthropic<1,>=0.26.0->langchain-anthropic) (1.3.1)\n",
      "Collecting tokenizers>=0.13.0 (from anthropic<1,>=0.26.0->langchain-anthropic)\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from anthropic<1,>=0.26.0->langchain-anthropic) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.43->langchain-anthropic) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.43->langchain-anthropic) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.43->langchain-anthropic) (0.1.60)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.43->langchain-anthropic) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.43->langchain-anthropic) (8.2.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.26.0->langchain-anthropic) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.26.0->langchain-anthropic) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.26.0->langchain-anthropic) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.26.0->langchain-anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.26.0->langchain-anthropic) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.43->langchain-anthropic) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.43->langchain-anthropic) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.43->langchain-anthropic) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.26.0->langchain-anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.26.0->langchain-anthropic) (2.18.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.0->anthropic<1,>=0.26.0->langchain-anthropic)\n",
      "  Using cached huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.26.0->langchain-anthropic) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.26.0->langchain-anthropic) (2024.3.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.26.0->langchain-anthropic) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.43->langchain-anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.43->langchain-anthropic) (2.2.1)\n",
      "Using cached langchain_anthropic-0.1.13-py3-none-any.whl (16 kB)\n",
      "Using cached anthropic-0.26.1-py3-none-any.whl (877 kB)\n",
      "Using cached jiter-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\n",
      "Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "Installing collected packages: jiter, huggingface-hub, tokenizers, anthropic, langchain-anthropic\n",
      "Successfully installed anthropic-0.26.1 huggingface-hub-0.23.1 jiter-0.1.0 langchain-anthropic-0.1.13 tokenizers-0.19.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.17\n",
    "!pip install faiss-cpu==1.8.0\n",
    "!pip install pypdf\n",
    "!pip install langchain_aws\n",
    "!pip install boto3\n",
    "!pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae351d-fa3b-4b05-a810-b30118a63cd1",
   "metadata": {},
   "source": [
    "# Set up Bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de55dc94-0bd1-4da5-b716-ad0f5fd6ba6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import load_tools, initialize_agent, Tool, AgentType\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.tools import tool, StructuredTool\n",
    "from typing import Optional, List, Any\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from PIL import Image\n",
    "from io import BytesIO, StringIO\n",
    "from IPython.display import display, Markdown, Pretty\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "import sys\n",
    "import textwrap\n",
    "import boto3\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2b2a05-78a9-40ca-9b5e-121030f9ede1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = os.environ.get(\"AWS_REGION\")\n",
    "boto3_bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee67162",
   "metadata": {},
   "source": [
    "# Get Bedrock LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8a161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameter = {\"temperature\": 0.0, \"top_p\": .5, \"max_tokens_to_sample\": 2000}\n",
    "modelId = \"anthropic.claude-v2\"\n",
    "llm = ChatBedrock(\n",
    "    model_id=modelId,\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\"temperature\": 0.1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc2e41",
   "metadata": {},
   "source": [
    "# Building an Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2d00e-aaf9-46b8-ae85-0f5a684b20f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ad721-ccbb-44e5-b9c6-f15ca2b75455",
   "metadata": {},
   "source": [
    "## 1.1 Weather tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64328fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool (\"get_lat_long\")\n",
    "def get_lat_long(place: str) -> dict:\n",
    "    \"\"\"Returns the latitude and longitude for a given place name as a dict object of python.\"\"\"\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    params = {'q': place, 'format': 'json', 'limit': 1}\n",
    "    response = requests.get(url, params=params, headers=headers).json()\n",
    "\n",
    "    if response:\n",
    "        lat = response[0][\"lat\"]\n",
    "        lon = response[0][\"lon\"]\n",
    "        return {\"latitude\": lat, \"longitude\": lon}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97236c3-0936-4162-9a4d-d60ddc4f1107",
   "metadata": {},
   "source": [
    "##  Try out the OSM API to retrieve coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02be2e9-d05f-4534-8c81-264fc1d35347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': '47.3744489', 'longitude': '8.5410422'}\n"
     ]
    }
   ],
   "source": [
    "# get the latitude and longitude for a certain location\n",
    "coordinates = get_lat_long(\"Zurich\")\n",
    "if not coordinates:\n",
    "    print(\"Something went wrong\")\n",
    "else:\n",
    "    print(coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b11d3d0-b9b8-421f-a019-785f1bec778f",
   "metadata": {},
   "source": [
    "# Task 1: The function below is incomplete. pls fix ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6187c68e-6c1a-47f9-93be-96b82959f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in the missing pieces of the function definition to create a get_weather function that calls the open-meteo API for getting the current weather based on input coordinates (latitude and longitude)\n",
    "# use the requests library to call the URI and\n",
    "# return the response as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d80ed4-7077-48c0-9806-789c161a7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool (\"get_weather\")\n",
    "def get_weather(latitude:str, longitude: str) -> dict:\n",
    "  \"\"\"Returns weather data for a given latitude and longitude.\"\"\"\n",
    "  url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
    "  response = requests.get(url)\n",
    "  return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "061988d0-281a-40a4-ae4a-87464a69a3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 47.38,\n",
       " 'longitude': 8.539999,\n",
       " 'generationtime_ms': 0.06389617919921875,\n",
       " 'utc_offset_seconds': 0,\n",
       " 'timezone': 'GMT',\n",
       " 'timezone_abbreviation': 'GMT',\n",
       " 'elevation': 416.0,\n",
       " 'current_weather_units': {'time': 'iso8601',\n",
       "  'interval': 'seconds',\n",
       "  'temperature': '°C',\n",
       "  'windspeed': 'km/h',\n",
       "  'winddirection': '°',\n",
       "  'is_day': '',\n",
       "  'weathercode': 'wmo code'},\n",
       " 'current_weather': {'time': '2024-05-21T19:45',\n",
       "  'interval': 900,\n",
       "  'temperature': 14.7,\n",
       "  'windspeed': 5.1,\n",
       "  'winddirection': 176,\n",
       "  'is_day': 0,\n",
       "  'weathercode': 80}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the weather for the retrived coordinates\n",
    "response = get_weather(coordinates)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3d438-376f-4a4f-b3d3-1f5688a3d0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40beae09-03a8-4765-bd9f-8e0bd7359e07",
   "metadata": {},
   "source": [
    "## Ask the LLM how the weather in Zurich is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "391f56f1-39a5-4143-bed1-1c4517bdc751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Unfortunately I don\\'t have direct access to real-time weather data for specific locations. However, I can suggest searching the web or using a weather app to look up the current weather conditions in Zurich. You could search for something like \"Zurich weather\" to find weather reports and forecasts for that city. Let me know if you need any other help finding weather information!', additional_kwargs={'usage': {'prompt_tokens': 20, 'completion_tokens': 80, 'total_tokens': 100}}, response_metadata={'model_id': 'anthropic.claude-v2', 'usage': {'prompt_tokens': 20, 'completion_tokens': 80, 'total_tokens': 100}}, id='run-8e09e9a0-85c2-44cc-8c53-841f1cd29bb1-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Can you check the weather in Zurich for me?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23771f7e-337a-4e05-8375-b05994bc0248",
   "metadata": {},
   "source": [
    "## It is not able ot answer, so let's add a tool to make it capable to do so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84727c20-15c1-41b9-9ac1-4d0cd81b28f8",
   "metadata": {},
   "source": [
    "## 1.2 Provide weather tool to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445b9ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool:name=get_lat_long::args={'place': {'title': 'Place', 'type': 'string'}}:: discription=get_lat_long(place: str) -> dict - Returns the latitude and longitude for a given place name as a dict object of python.::"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tool:name=get_weather::args={'latitude': {'title': 'Latitude', 'type': 'string'}, 'longitude': {'title': 'Longitude', 'type': 'string'}}:: discription=get_weather(latitude: str, longitude: str) -> dict - Returns weather data for a given latitude and longitude.::"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tools_list = [get_lat_long, get_weather]\n",
    "for tools_s in tools_list:\n",
    "    display(Pretty((f\"Tool:name={tools_s.name}::args={tools_s.args}:: discription={tools_s.description}::\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3e1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The prompt:template:used:was ---- > \\n'\n",
      " '\\n'\n",
      " \"input_variables=['agent_scratchpad', 'input'] \"\n",
      " 'messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], '\n",
      " \"template='Respond to the human as helpfully and accurately as possible. You \"\n",
      " 'have access to the following tools:\\\\n\\\\nget_lat_long: get_lat_long(place: '\n",
      " 'str) -> dict - Returns the latitude and longitude for a given place name as '\n",
      " \"a dict object of python., args: {{\\\\'place\\\\': {{\\\\'title\\\\': \\\\'Place\\\\', \"\n",
      " \"\\\\'type\\\\': \\\\'string\\\\'}}}}\\\\nget_weather: get_weather(latitude: str, \"\n",
      " 'longitude: str) -> dict - Returns weather data for a given latitude and '\n",
      " \"longitude., args: {{\\\\'latitude\\\\': {{\\\\'title\\\\': \\\\'Latitude\\\\', \"\n",
      " \"\\\\'type\\\\': \\\\'string\\\\'}}, \\\\'longitude\\\\': {{\\\\'title\\\\': \\\\'Longitude\\\\', \"\n",
      " \"\\\\'type\\\\': \\\\'string\\\\'}}}}\\\\n\\\\nUse a json blob to specify a tool by \"\n",
      " 'providing an action key (tool name) and an action_input key (tool '\n",
      " 'input).\\\\n\\\\nValid \"action\" values: \"Final Answer\" or get_lat_long, '\n",
      " 'get_weather\\\\n\\\\nProvide only ONE action per $JSON_BLOB, as '\n",
      " 'shown:\\\\n\\\\n```\\\\n{{\\\\n  \"action\": $TOOL_NAME,\\\\n  \"action_input\": '\n",
      " '$INPUT\\\\n}}\\\\n```\\\\n\\\\nFollow this format:\\\\n\\\\nQuestion: input question to '\n",
      " 'answer\\\\nThought: consider previous and subsequent '\n",
      " 'steps\\\\nAction:\\\\n```\\\\n$JSON_BLOB\\\\n```\\\\nObservation: action result\\\\n... '\n",
      " '(repeat Thought/Action/Observation N times)\\\\nThought: I know what to '\n",
      " 'respond\\\\nAction:\\\\n```\\\\n{{\\\\n  \"action\": \"Final Answer\",\\\\n  '\n",
      " '\"action_input\": \"Final response to human\"\\\\n}}\\\\n```\\\\n\\\\nBegin! Reminder to '\n",
      " 'ALWAYS respond with a valid json blob of a single action. Use tools if '\n",
      " 'necessary. Respond directly if appropriate. Format is '\n",
      " \"Action:```$JSON_BLOB```then Observation:.\\\\nThought:')), \"\n",
      " \"HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', \"\n",
      " \"'input'], template='{input}\\\\n\\\\n{agent_scratchpad}'))]\\n\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm_agent = initialize_agent(\n",
    "    tools_list, \n",
    "    llm, \n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, #SELF_ASK_WITH_SEARCH,# CONVERSATIONAL_REACT_DESCRIPTION, # ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True,\n",
    "    max_iteration=3,\n",
    "    return_intermediate_steps=True,\n",
    "    max_execution_time=60\n",
    ")\n",
    "pprint(f\"The prompt:template:used:was ---- > \\n\\n{llm_agent.agent.llm_chain.prompt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "225200f4-cb2d-447d-b1dd-b7822a7b0f58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLet me check on that for you.\n",
      "\n",
      "Thought: To look up the weather in Zurich, I first need to get the latitude and longitude coordinates for Zurich. I can use the get_lat_long tool for that.\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"get_lat_long\",\n",
      "  \"action_input\": \"Zurich\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'latitude': '47.3744489', 'longitude': '8.5410422'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have the latitude and longitude for Zurich, I can use the get_weather tool to get the current weather data for that location.\n",
      "\n",
      "Action:\n",
      "```json  \n",
      "{\n",
      "  \"action\": \"get_weather\",\n",
      "  \"action_input\": {\n",
      "    \"latitude\": \"47.3744489\",\n",
      "    \"longitude\": \"8.5410422\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'latitude': 47.38, 'longitude': 8.539999, 'generationtime_ms': 0.048995018005371094, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 416.0, 'current_weather_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature': '°C', 'windspeed': 'km/h', 'winddirection': '°', 'is_day': '', 'weathercode': 'wmo code'}, 'current_weather': {'time': '2024-05-21T19:45', 'interval': 900, 'temperature': 14.7, 'windspeed': 5.1, 'winddirection': 176, 'is_day': 0, 'weathercode': 80}}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere is the current weather in Zurich based on the latitude and longitude I looked up:\n",
      "\n",
      "The current temperature is 14.7°C. The wind speed is 5.1 km/h from the south (176°). The weather code indicates broken clouds. This data is as of 7:45 PM local Zurich time.\n",
      "\n",
      "Let me know if you need any other weather information for Zurich!\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\", \n",
      "  \"action_input\": \"Here is the current weather in Zurich based on the latitude and longitude I looked up:\n",
      "\n",
      "The current temperature is 14.7°C. The wind speed is 5.1 km/h from the south (176°). The weather code indicates broken clouds. This data is as of 7:45 PM local Zurich time.  \n",
      "\n",
      "Let me know if you need any other weather information for Zurich!\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you check the weather in Zurich for me?',\n",
       " 'output': 'Here is the current weather in Zurich based on the latitude and longitude I looked up:\\n\\nThe current temperature is 14.7°C. The wind speed is 5.1 km/h from the south (176°). The weather code indicates broken clouds. This data is as of 7:45 PM local Zurich time.  \\n\\nLet me know if you need any other weather information for Zurich!',\n",
       " 'intermediate_steps': [(AgentAction(tool='get_lat_long', tool_input='Zurich', log='Let me check on that for you.\\n\\nThought: To look up the weather in Zurich, I first need to get the latitude and longitude coordinates for Zurich. I can use the get_lat_long tool for that.\\n\\nAction:\\n```json\\n{\\n  \"action\": \"get_lat_long\",\\n  \"action_input\": \"Zurich\"\\n}\\n```\\n\\n'),\n",
       "   {'latitude': '47.3744489', 'longitude': '8.5410422'}),\n",
       "  (AgentAction(tool='get_weather', tool_input={'latitude': '47.3744489', 'longitude': '8.5410422'}, log='Now that I have the latitude and longitude for Zurich, I can use the get_weather tool to get the current weather data for that location.\\n\\nAction:\\n```json  \\n{\\n  \"action\": \"get_weather\",\\n  \"action_input\": {\\n    \"latitude\": \"47.3744489\",\\n    \"longitude\": \"8.5410422\"\\n  }\\n}\\n```\\n\\n'),\n",
       "   {'latitude': 47.38,\n",
       "    'longitude': 8.539999,\n",
       "    'generationtime_ms': 0.048995018005371094,\n",
       "    'utc_offset_seconds': 0,\n",
       "    'timezone': 'GMT',\n",
       "    'timezone_abbreviation': 'GMT',\n",
       "    'elevation': 416.0,\n",
       "    'current_weather_units': {'time': 'iso8601',\n",
       "     'interval': 'seconds',\n",
       "     'temperature': '°C',\n",
       "     'windspeed': 'km/h',\n",
       "     'winddirection': '°',\n",
       "     'is_day': '',\n",
       "     'weathercode': 'wmo code'},\n",
       "    'current_weather': {'time': '2024-05-21T19:45',\n",
       "     'interval': 900,\n",
       "     'temperature': 14.7,\n",
       "     'windspeed': 5.1,\n",
       "     'winddirection': 176,\n",
       "     'is_day': 0,\n",
       "     'weathercode': 80}})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_agent.invoke({\"input\": \"Can you check the weather in Zurich for me?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12af92-4bf7-41c2-9db4-7575cd2b9896",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Create retriever tool for RAG (retrieval augmented generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3935c54-c5a6-46eb-896b-dbd4ceeec54f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 Create Vector DB in memory with Amazon SageMaker FAQ as content\n",
    "The file can be [found here](./rag_data/Amazon_SageMaker_FAQs.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8796092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functools.partial(<function _get_relevant_documents at 0x7f8815fd1750>, retriever=VectorStoreRetriever(tags=['FAISS', 'BedrockEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f880845b400>, search_kwargs={'k': 4}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'RetrieverInput',\n",
       " 'description': 'Input to the retriever.',\n",
       " 'type': 'object',\n",
       " 'properties': {'query': {'title': 'Query',\n",
       "   'description': 'query to look up in retriever',\n",
       "   'type': 'string'}},\n",
       " 'required': ['query']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "loader = PyPDFLoader(\"./rag_data/Amazon_SageMaker_FAQs.pdf\")\n",
    "bedrock_client = boto3_bedrock\n",
    "texts = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0).split_documents(loader.load())\n",
    "embed_model = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_client)\n",
    "#- create the vector store\n",
    "db = FAISS.from_documents(texts, embed_model)\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "tool_search = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"search_sagemaker_policy\",\n",
    "    description=\"Searches and returns excerpts for any question about SageMaker\",\n",
    ")\n",
    "pprint(tool_search.func)\n",
    "tool_search.args_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2ba27-91ed-48ed-a91d-a7901702b17b",
   "metadata": {},
   "source": [
    "# Task 2: Based on the implementation from above, please add the retriever functionality as tool and initialize the agent again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b105b09-6b44-4982-b0ad-7506ddf8ae73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write your code here, no imports are needed. Take the retriever tool from above and integrate it into the LLM, to be able to interact with the SageMaker FAQ document\n",
    "\n",
    "# add the retriever tool to our toolset\n",
    "tools_list.append(tool_search)\n",
    "\n",
    "# Construct the Tools agent and also the executor\n",
    "llm_agent = initialize_agent(\n",
    "    tools_list, \n",
    "    llm, \n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, #SELF_ASK_WITH_SEARCH,# CONVERSATIONAL_REACT_DESCRIPTION, # ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True,\n",
    "    max_iteration=4,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec23f7",
   "metadata": {},
   "source": [
    "## Let's test the retriever tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138ff91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLet me provide some information on Amazon SageMaker pipelines:\n",
      "\n",
      "Thought: To answer the question about what a SageMaker pipeline is, I will first get an overview summary by using the search_sagemaker_policy tool.\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"search_sagemaker_policy\",\n",
      "  \"action_input\": \"what is a sagemaker pipeline\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mgoals. You can track data, code, trained models, and more with SageMaker Pipelines.\"How does the pricing for Amazon SageMaker Pipelines work?,There is no additional charge for Amazon SageMaker Pipelines. You pay only for the underlying compute or any separate AWS services you use within SageMaker Pipelines.Can I use Kubeflow with Amazon SageMaker?,\"Yes. Amazon SageMaker Components for Kubeflow Pipelines are open-source plugins that allow you to use Kubeflow Pipelines to define your ML workflows and use SageMaker for the data labeling, training, and inference steps. Kubeflow Pipelines is an add-on to Kubeflow that lets you build and deploy portable and scalable end-to-end ML pipelines. However, when using Kubeflow Pipelines, ML ops teams need to manage a Kubernetes cluster with CPU and GPU instances and keep its utilization high at all times to reduce operational costs. Maximizing the utilization of a cluster across data science teams is challenging and adds additional operational overhead to the ML ops teams. As an alternative to an ML-optimized Kubernetes cluster, with SageMaker Components for Kubeflow Pipelines you can take advantage of powerful SageMaker features such as data labeling, fully managed large-scale hyperparameter tuning and distributed training jobs, one-click secure and scalable model deployment, and cost-effective training through Amazon EC2 Spot instances without needing to configure and manage Kubernetes clusters specifically to run the ML jobs.\"How does Amazon SageMaker Components for Kubeflow Pipelines pricing work?,There is no additional charge for using Amazon SageMaker Components for Kubeflow Pipelines. How can Amazon SageMaker prepare data for ML?,\"Amazon SageMaker Data Wrangler reduces the time it takes to aggregate and prepare data for ML. From a single interface in Amazon SageMaker Studio, you can browse and import data from Amazon S3, Amazon Athena, Amazon Redshift, AWS Lake Formation, Amazon SageMaker Feature Store, and Snowflake in just a few clicks. You can also query and import data that is transferred from over 40 data sources and registered in AWS Glue Data Catalog by Amazon AppFlow. SageMaker Data Wrangler will automatically load, aggregate, and display the raw data. After importing your data into SageMaker Data Wrangler, you can see automatically generated column summaries and histograms. You can then dig deeper to understand your data and identify potential errors with the SageMaker Data Wrangler Data Quality and Insights report, which provides summary statistics and data quality warnings. You can also run bias analysis supported by Amazon SageMaker Clarify directly from SageMaker Data Wrangler to detect potential bias during data preparation. From there, you can use SageMaker Data Wrangler’s pre-built transformations to prepare your data. Once your data is prepared, you can build fully automated ML workflows with Amazon SageMaker Pipelines or import that data into Amazon SageMaker Feature Store.\"How can I create model features with Amazon SageMaker Data Wrangler?,\"Without writing a single line of code, Amazon SageMaker Data Wrangler can automatically transform your data into new features.\n",
      "\n",
      "service with an intuitive, point-and-click interface that lets you create highly accurate ML-based predictions from your data. SageMaker Canvas lets you access and combine data from a variety of sources using a drag-and-drop user interface, automatically cleaning and preparing data to minimize manual cleanup. SageMaker Canvas applies a variety of state-of-the-art ML algorithms to find highly accurate predictive models and provides an intuitive interface to make predictions. You can use SageMaker Canvas to make much more precise predictions in a variety of business applications and easily collaborate with data scientists and analysts in your enterprise by sharing your models, data, and reports. To learn more about SageMaker Canvas, please visit the SageMaker Canvas FAQ page.\"\"How does Amazon SageMaker Canvas pricing work?\",\"With Amazon SageMaker Canvas, you pay based on usage. SageMaker Canvas lets you interactively ingest, explore, and prepare your data from multiple sources, train highly accurate ML models with your data, and generate predictions. There are two components that determine your bill: session charges based on the number of hours for which SageMaker Canvas is used or logged into, and charges for training the model based on the size of the dataset used to build the model. For more information see the SageMaker Canvas pricing page.\"How can I build a continuous integration and delivery (CI/CD) pipeline with Amazon SageMaker?,\"Amazon SageMaker Pipelines helps you create fully automated ML workflows from data preparation through model deployment so you can scale to thousands of ML models in production. SageMaker Pipelines comes with a Python SDK that connects to Amazon SageMaker Studio so you can take advantage of a visual interface to build each step of the workflow. Then using a single API, you can connect each step to create an end-to-end workflow. SageMaker Pipelines takes care of managing data between steps, packaging the code recipes, and orchestrating their execution, reducing months of coding to a few hours. Every time a workflow executes, a complete record of the data processed and actions taken is kept so data scientists and ML developers can quickly debug problems.\"How do I view all my trained models to choose the best model to move to production?,\"Amazon SageMaker Pipelines provides a central repository of trained models called a model registry. You can discover models and access the model registry visually through SageMaker Studio or programmatically through the Python SDK, making it easy to choose your desired model to deploy into production.\"What components of Amazon SageMaker can be added to Amazon SageMaker Pipelines?,\"The components available through Amazon SageMaker Studio, including Amazon SageMaker Amazon Clarify, Amazon SageMaker Data Wrangler, Amazon SageMaker Feature Store, Amazon SageMaker Experiments, Amazon SageMaker Debugger, and Amazon SageMaker Model Monitor, can be added to SageMaker Pipelines.\"How do I track my model components across the entire ML workflow?,\"Amazon SageMaker Pipelines automatically keeps track of all model constituents and keeps an audit trail of all changes, thereby eliminating manual tracking, and can help you achieve compliance\n",
      "\n",
      "common governance constructs such as network access boundaries and encryption keys. SageMaker Role Manager will then generate the IAM policy automatically. You can discover the generated role and associated policies through the AWS IAM console. To further tailor the permissions to your use case, attach your managed IAM policies to the IAM role that you create with SageMaker Role Manager. You can also add tags to help identify the role and organize across AWS services.\"What does Amazon SageMaker Model Cards do?,Amazon SageMaker Model Cards helps you centralize and standardize model documentation throughout the ML lifecycle by creating a single source of truth for model information. SageMaker Model Cards auto-populates training details to accelerate the documentation process. You can also add details such as the purpose of the model and the performance goals. You can attach model evaluation results to your model card and provide visualizations to gain key insights into model performance. SageMaker Model Cards can easily be shared with others by exporting to a pdf format.What does Amazon SageMaker Model Dashboard do? ,\"Amazon SageMaker Model Dashboard gives you a comprehensive overview of deployed models and endpoints, letting you track resources and model behavior violations through one pane. It allows you to monitor model behavior in four dimensions, including data and model quality, and bias and feature attribution drift through its integration with Amazon SageMaker Model Monitor and Amazon SageMaker Clarify. SageMaker Model Dashboard also provides an integrated experience to set up and receive alerts for missing and inactive model monitoring jobs, and deviations in model behavior for model quality, data quality, bias drift, and feature attribution drift. You can further inspect individual models and analyze factors impacting model performance over time. Then, you can follow up with ML practitioners to take corrective measures.\"What is Amazon SageMaker Autopilot?,\"Amazon SageMaker Autopilot is the industry’s first automated machine learning capability that gives you complete control and visibility into your ML models. SageMaker Autopilot automatically inspects raw data, applies feature processors, picks the best set of algorithms, trains and tunes multiple models, tracks their performance, and then ranks the models based on performance, all with just a few clicks. The result is the best-performing model that you can deploy at a fraction of the time normally required to train the model. You get full visibility into how the model was created and what’s in it, and SageMaker Autopilot integrates with Amazon SageMaker Studio. You can explore up to 50 different models generated by SageMaker Autopilot inside SageMaker Studio so it’s easy to pick the best model for your use case. SageMaker Autopilot can be used by people without ML experience to easily produce a model, or it can be used by experienced developers to quickly develop a baseline model on which teams can further iterate.\"What built-in algorithms are supported in Amazon SageMaker Autopilot?,Amazon SageMaker Autopilot supports 2 built-in algorithms: XGBoost and Linear Learner.Can I stop an Amazon SageMaker Autopilot job manually?,\"Yes. You can\n",
      "\n",
      "What is Amazon SageMaker Experiments?,\"Amazon SageMaker Experiments helps you organize and track iterations to ML models. SageMaker Experiments helps you manage iterations by automatically capturing the input parameters, configurations, and results, and storing them as \"\"experiments\"\". You can work within the visual interface of Amazon SageMaker Studio, where you can browse active experiments, search for previous experiments by their characteristics, review previous experiments with their results, and compare experiment results visually.\"What is Amazon SageMaker Debugger?,\"Amazon SageMaker Debugger automatically captures real-time metrics during training, such as confusion matrices and learning gradients, to help improve model accuracy. The metrics from SageMaker Debugger can be visualized in Amazon SageMaker Studio for easy understanding. SageMaker Debugger can also generate warnings and remediation advice when common training problems are detected. SageMaker Debugger also automatically monitors and profiles system resources such as CPUs, GPUs, network, and memory in real time, and provides recommendations on re-allocation of these resources. This enables you to use your resources efficiently during training and helps reduce costs and resources.\"Does Amazon SageMaker support distributed training?,\"Yes. Amazon SageMaker can automatically distribute deep learning models and large training sets across AWS GPU instances in a fraction of the time it takes to build and optimize these distribution strategies manually. The two distributed training techniques that SageMaker applies are data parallelism and model parallelism. Data parallelism is applied to improve training speeds by dividing the data equally across multiple GPU instances, allowing each instance to train concurrently. Model parallelism is useful for models too large to be stored on a single GPU and require the model to be partitioned into smaller parts before distributing across multiple GPUs. With only a few lines of additional code in your PyTorch and TensorFlow training scripts, SageMaker will automatically apply data parallelism or model parallelism for you, allowing you to develop and deploy your models faster. SageMaker will determine the best approach to split your model by using graph partitioning algorithms to balance the computation of each GPU while minimizing the communication between GPU instances. SageMaker also optimizes your distributed training jobs through algorithms that fully utilize the AWS compute and network in order to achieve near-linear scaling efficiency, which allows you to complete training faster than manual open-source implementations.\"What is Amazon SageMaker Training Compiler?,\"Amazon SageMaker Training Compiler is a deep learning (DL) compiler that accelerates DL model training by up to 50 percent through graph- and kernel-level optimizations to use GPUs more efficiently. SageMaker Training Compiler is integrated with versions of TensorFlow and PyTorch in SageMaker, so you can speed up training in these popular frameworks with minimal code changes.\"How does Amazon SageMaker Training Compiler work?,\"Amazon SageMaker Training Compiler accelerates training jobs by converting DL models\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere are the key points about Amazon SageMaker Pipelines:\n",
      "\n",
      "- SageMaker Pipelines helps you build, automate, manage, and track end-to-end ML workflows.\n",
      "\n",
      "- It provides a visual interface in SageMaker Studio to build pipelines and connect different steps like data processing, model training, evaluation, and deployment.\n",
      "\n",
      "- It keeps track of all the data, parameters, configurations, and results as you build models. This provides full traceability and reproducibility of your workflows.\n",
      "\n",
      "- SageMaker Pipelines can help you manage thousands of production models by tracking model artifacts and metadata in a central repository called the Model Registry.\n",
      "\n",
      "- The components available in SageMaker like Data Wrangler, Feature Store, Clarify, Debugger etc. can be easily integrated into the pipelines.\n",
      "\n",
      "- It generates reports and visualizations to help observe pipeline progress and pinpoint issues.\n",
      "\n",
      "- SageMaker Pipelines automates the execution of each step and manages the underlying infrastructure. This eliminates a lot of manual work.\n",
      "\n",
      "- There are no additional charges for SageMaker Pipelines. You only pay for the underlying services used.\n",
      "\n",
      "In summary, SageMaker Pipelines provides a complete ML workflow orchestration service to help you build, track, manage, and deploy models at scale.\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\", \n",
      "  \"action_input\": \"Amazon SageMaker Pipelines is a service that helps you build, automate, manage and track end-to-end ML workflows. It provides a visual interface to build pipelines that connect data processing, training, evaluation and deployment steps. SageMaker Pipelines keeps track of all data, parameters and results for full traceability of workflows. It generates reports to observe pipeline progress and comes integrated with other SageMaker components. SageMaker Pipelines helps manage thousands of production models and automates execution of each step in a workflow.\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is a Amazon SageMaker pipeline?',\n",
       " 'output': 'Amazon SageMaker Pipelines is a service that helps you build, automate, manage and track end-to-end ML workflows. It provides a visual interface to build pipelines that connect data processing, training, evaluation and deployment steps. SageMaker Pipelines keeps track of all data, parameters and results for full traceability of workflows. It generates reports to observe pipeline progress and comes integrated with other SageMaker components. SageMaker Pipelines helps manage thousands of production models and automates execution of each step in a workflow.',\n",
       " 'intermediate_steps': [(AgentAction(tool='search_sagemaker_policy', tool_input='what is a sagemaker pipeline', log='Let me provide some information on Amazon SageMaker pipelines:\\n\\nThought: To answer the question about what a SageMaker pipeline is, I will first get an overview summary by using the search_sagemaker_policy tool.\\n\\nAction:\\n```json\\n{\\n  \"action\": \"search_sagemaker_policy\",\\n  \"action_input\": \"what is a sagemaker pipeline\"\\n}\\n```\\n\\n'),\n",
       "   'goals. You can track data, code, trained models, and more with SageMaker Pipelines.\"How does the pricing for Amazon SageMaker Pipelines work?,There is no additional charge for Amazon SageMaker Pipelines. You pay only for the underlying compute or any separate AWS services you use within SageMaker Pipelines.Can I use Kubeflow with Amazon SageMaker?,\"Yes. Amazon SageMaker Components for Kubeflow Pipelines are open-source plugins that allow you to use Kubeflow Pipelines to define your ML workflows and use SageMaker for the data labeling, training, and inference steps. Kubeflow Pipelines is an add-on to Kubeflow that lets you build and deploy portable and scalable end-to-end ML pipelines. However, when using Kubeflow Pipelines, ML ops teams need to manage a Kubernetes cluster with CPU and GPU instances and keep its utilization high at all times to reduce operational costs. Maximizing the utilization of a cluster across data science teams is challenging and adds additional operational overhead to the ML ops teams. As an alternative to an ML-optimized Kubernetes cluster, with SageMaker Components for Kubeflow Pipelines you can take advantage of powerful SageMaker features such as data labeling, fully managed large-scale hyperparameter tuning and distributed training jobs, one-click secure and scalable model deployment, and cost-effective training through Amazon EC2 Spot instances without needing to configure and manage Kubernetes clusters specifically to run the ML jobs.\"How does Amazon SageMaker Components for Kubeflow Pipelines pricing work?,There is no additional charge for using Amazon SageMaker Components for Kubeflow Pipelines.\\xa0How can Amazon SageMaker prepare data for ML?,\"Amazon SageMaker Data Wrangler reduces the time it takes to aggregate and prepare data for ML. From a single interface in Amazon SageMaker Studio, you can browse and import data from Amazon S3, Amazon Athena, Amazon Redshift, AWS Lake Formation, Amazon SageMaker Feature Store, and Snowflake in just a few clicks. You can also query and import data that is transferred from over 40 data sources and registered in AWS Glue Data Catalog by Amazon AppFlow. SageMaker Data Wrangler will automatically load, aggregate, and display the raw data. After importing your data into SageMaker Data Wrangler, you can see automatically generated column summaries and histograms. You can then dig deeper to understand your data and identify potential errors with the SageMaker Data Wrangler Data Quality and Insights report, which provides summary statistics and data quality warnings. You can also run bias analysis supported by Amazon SageMaker Clarify directly from SageMaker Data Wrangler to detect potential bias during data preparation. From there, you can use SageMaker Data Wrangler’s pre-built transformations to prepare your data. Once your data is prepared, you can build fully automated ML workflows with Amazon SageMaker Pipelines or import that data into\\xa0Amazon SageMaker Feature Store.\"How can I create model features with Amazon SageMaker Data Wrangler?,\"Without writing a single line of code, Amazon SageMaker Data Wrangler can automatically transform your data into new features.\\n\\nservice with an intuitive, point-and-click interface that lets you create highly accurate ML-based predictions from your data. SageMaker Canvas lets you access and combine data from a variety of sources using a drag-and-drop user interface, automatically cleaning and preparing data to minimize manual cleanup. SageMaker Canvas applies a variety of state-of-the-art ML algorithms to find highly accurate predictive models and provides an intuitive interface to make predictions. You can use SageMaker Canvas to make much more precise predictions in a variety of business applications and easily collaborate with data scientists and analysts in your enterprise by sharing your models, data, and reports. To learn more about SageMaker Canvas, please visit the\\xa0SageMaker Canvas FAQ\\xa0page.\"\"How does Amazon SageMaker Canvas pricing work?\",\"With Amazon SageMaker Canvas, you pay based on usage. SageMaker Canvas lets you interactively ingest, explore, and prepare your data from multiple sources, train highly accurate ML models with your data, and generate predictions. There are two components that determine your bill: session charges based on the number of hours for which SageMaker Canvas is used or logged into, and charges for training the model based on the size of the dataset used to build the model. For more information see the SageMaker Canvas pricing page.\"How can I build a continuous integration and delivery (CI/CD) pipeline with Amazon SageMaker?,\"Amazon SageMaker Pipelines\\xa0helps you create fully automated ML workflows from data preparation through model deployment so you can scale to thousands of ML models in production. SageMaker Pipelines comes with a Python SDK that connects to Amazon SageMaker Studio so you can take advantage of a visual interface to build each step of the workflow. Then using a single API, you can connect each step to create an end-to-end workflow. SageMaker Pipelines takes care of managing data between steps, packaging the code recipes, and orchestrating their execution, reducing months of coding to a few hours. Every time a workflow executes, a complete record of the data processed and actions taken is kept so data scientists and ML developers can quickly debug problems.\"How do I view all my trained models to choose the best model to move to production?,\"Amazon SageMaker Pipelines provides a central repository of trained models called a model registry. You can discover models and access the model registry visually through SageMaker Studio or programmatically through the Python SDK, making it easy to choose your desired model to deploy into production.\"What components of Amazon SageMaker can be added to Amazon SageMaker Pipelines?,\"The components available through Amazon SageMaker Studio, including Amazon SageMaker Amazon Clarify, Amazon SageMaker Data Wrangler, Amazon SageMaker Feature Store, Amazon SageMaker Experiments, Amazon SageMaker Debugger, and Amazon SageMaker Model Monitor, can be added to SageMaker Pipelines.\"How do I track my model components across the entire ML workflow?,\"Amazon SageMaker Pipelines automatically keeps track of all model constituents and keeps an audit trail of all changes, thereby eliminating manual tracking, and can help you achieve compliance\\n\\ncommon governance constructs such as network access boundaries and encryption keys. SageMaker Role Manager will then generate the IAM policy automatically. You can discover the generated role and associated policies through the AWS IAM console. To further tailor the permissions to your use case, attach your managed IAM policies to the IAM role that you create with SageMaker Role Manager. You can also add tags to help identify the role and organize across AWS services.\"What does Amazon SageMaker Model Cards do?,Amazon SageMaker Model Cards helps you centralize and standardize model documentation throughout the ML lifecycle by creating a single source of truth for model information. SageMaker Model Cards auto-populates training details to accelerate the documentation process. You can also add details such as the purpose of the model and the performance goals. You can attach model evaluation results to your model card and provide visualizations to gain key insights into model performance. SageMaker Model Cards can easily be shared with others by exporting to a pdf format.What does Amazon SageMaker Model Dashboard do?\\xa0,\"Amazon SageMaker Model Dashboard gives you a comprehensive overview of deployed models and endpoints, letting you track resources and model behavior violations through one pane. It allows you to monitor model behavior in four dimensions, including data and model quality, and bias and feature attribution drift through its integration with Amazon SageMaker Model Monitor and Amazon SageMaker Clarify. SageMaker Model Dashboard also provides an integrated experience to set up and receive alerts for missing and inactive model monitoring jobs, and deviations in model behavior for model quality, data quality, bias drift, and feature attribution drift. You can further inspect individual models and analyze factors impacting model performance over time. Then, you can follow up with ML practitioners to take corrective measures.\"What is Amazon SageMaker Autopilot?,\"Amazon SageMaker Autopilot\\xa0is\\xa0the industry’s first automated machine learning capability that gives you complete control and visibility into your ML models. SageMaker Autopilot automatically inspects raw data, applies feature processors, picks the best set of algorithms, trains and tunes multiple models, tracks their performance, and then ranks the models based on performance, all with just a few clicks. The result is the best-performing model that you can deploy at a fraction of the time normally required to train the model. You get full visibility into how the model was created and what’s in it, and SageMaker Autopilot integrates with Amazon SageMaker Studio. You can explore up to 50 different models generated by SageMaker Autopilot inside SageMaker Studio so it’s easy to pick the best model for your use case. SageMaker Autopilot can be used by people without ML experience to easily produce a model, or it can be used by experienced developers to quickly develop a baseline model on which teams can further iterate.\"What built-in algorithms are supported in Amazon SageMaker Autopilot?,Amazon SageMaker Autopilot supports 2 built-in algorithms: XGBoost and Linear Learner.Can I stop an Amazon SageMaker Autopilot job manually?,\"Yes. You can\\n\\nWhat is Amazon SageMaker Experiments?,\"Amazon SageMaker Experiments helps you organize and track iterations to ML models. SageMaker Experiments helps you manage iterations by automatically capturing the input parameters, configurations, and results, and storing them as \"\"experiments\"\". You can work within the visual interface of Amazon SageMaker Studio, where you can browse active experiments, search for previous experiments by their characteristics, review previous experiments with their results, and compare experiment results visually.\"What is Amazon SageMaker Debugger?,\"Amazon SageMaker Debugger automatically captures real-time metrics during training, such as confusion matrices and learning gradients, to help improve model accuracy. The metrics from SageMaker Debugger can be visualized in Amazon SageMaker Studio for easy understanding. SageMaker Debugger can also generate warnings and remediation advice when common training problems are detected. SageMaker Debugger also automatically monitors and profiles system resources such as CPUs, GPUs, network, and memory in real time, and provides recommendations on re-allocation of these resources. This enables you to use your resources efficiently during training and helps reduce costs and resources.\"Does Amazon SageMaker support distributed training?,\"Yes. Amazon SageMaker can automatically distribute deep learning models and large training sets across AWS GPU instances in a fraction of the time it takes to build and optimize these distribution strategies manually. The two distributed training techniques that SageMaker applies are data parallelism and model parallelism. Data parallelism is applied to improve training speeds by dividing the data equally across multiple GPU instances, allowing each instance to train concurrently. Model parallelism is useful for models too large to be stored on a single GPU and require the model to be partitioned into smaller parts before distributing across multiple GPUs. With only a few lines of additional code in your PyTorch and TensorFlow training scripts, SageMaker will automatically apply data parallelism or model parallelism for you, allowing you to develop and deploy your models faster. SageMaker will determine the best approach to split your model by using graph partitioning algorithms to balance the computation of each GPU while minimizing the communication between GPU instances. SageMaker also optimizes your distributed training jobs through algorithms that fully utilize the AWS compute and network in order to achieve near-linear scaling efficiency, which allows you to complete training faster than manual open-source implementations.\"What is Amazon SageMaker Training Compiler?,\"Amazon SageMaker Training Compiler is a deep learning (DL) compiler that accelerates DL model training by up to 50 percent through graph- and kernel-level optimizations to use GPUs more efficiently. SageMaker Training Compiler is integrated with versions of TensorFlow and PyTorch in SageMaker, so you can speed up training in these popular frameworks with minimal code changes.\"How does Amazon SageMaker Training Compiler work?,\"Amazon SageMaker Training Compiler accelerates training jobs by converting DL models')]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After finishing, test your new tool by running this cell\n",
    "llm_agent.invoke({\"input\": \"What is a Amazon SageMaker pipeline?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "356fdbf3-7956-4b32-af30-d078dcc0c2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLet me check on that for you.\n",
      "\n",
      "Thought: To look up the weather in New York, I first need to get the latitude and longitude coordinates for New York using the get_lat_long tool. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"get_lat_long\",\n",
      "  \"action_input\": \"New York\" \n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'latitude': '40.7127281', 'longitude': '-74.0060152'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have the latitude and longitude for New York, I can use the get_weather tool to get the current weather data for those coordinates.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"get_weather\",\n",
      "  \"action_input\": \"40.7127281\", \n",
      "  \"action_input\": \"-74.0060152\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for get_weatherSchema\nlongitude\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's check whether the weather tool is still working\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mllm_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow is the weather in New York\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1432\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1432\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1441\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1442\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1138\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1138\u001b[0m         [\n\u001b[1;32m   1139\u001b[0m             a\n\u001b[1;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1142\u001b[0m                 color_mapping,\n\u001b[1;32m   1143\u001b[0m                 inputs,\n\u001b[1;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1145\u001b[0m                 run_manager,\n\u001b[1;32m   1146\u001b[0m             )\n\u001b[1;32m   1147\u001b[0m         ]\n\u001b[1;32m   1148\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1138\u001b[0m         [\n\u001b[1;32m   1139\u001b[0m             a\n\u001b[1;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1142\u001b[0m                 color_mapping,\n\u001b[1;32m   1143\u001b[0m                 inputs,\n\u001b[1;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1145\u001b[0m                 run_manager,\n\u001b[1;32m   1146\u001b[0m             )\n\u001b[1;32m   1147\u001b[0m         ]\n\u001b[1;32m   1148\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1223\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m-> 1223\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1245\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1245\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/tools.py:417\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n\u001b[0;32m--> 417\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    419\u001b[0m         observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool input validation error\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/tools.py:406\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    405\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m--> 406\u001b[0m parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    408\u001b[0m observation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[1;32m    414\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/tools.py:300\u001b[0m, in \u001b[0;36mBaseTool._parse_input\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m         key_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(input_args\u001b[38;5;241m.\u001b[39m__fields__\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m--> 300\u001b[0m         \u001b[43minput_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tool_input\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydantic/v1/main.py:711\u001b[0m, in \u001b[0;36mBaseModel.validate\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    708\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_dict_if_root(value)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39morm_mode:\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_orm(value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for get_weatherSchema\nlongitude\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "# Let's check whether the weather tool is still working\n",
    "llm_agent.invoke({\"input\": \"How is the weather in New York\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb725970-34f9-4829-bf30-6ea08430d29b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Build a dog image tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed721794-9ab0-4c7a-b24c-626c804f6d92",
   "metadata": {},
   "source": [
    "# Task 3: Build a tool for the LLM that fetches images from different dog breeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca72d54-5b57-4f96-aaf5-f16c4695e8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please use the Dog API (https://dog.ceo/dog-api/documentation), and more specifically the random breed endpoint (https://dog.ceo/dog-api/breeds-list)\n",
    "# Based on a breed input, the LLM should have a tool available to call the API\n",
    "# at the end of the notebook, you can find code to display the image, the task is done, if you can display a random image based on the LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bb57a-865e-4504-9cdc-1c4722730239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool (\"get_dog_image\")\n",
    "def get_dog_image(breed: str) -> dict:\n",
    "    \"\"\"Returns the latitude and longitude for a given place name as a dict object of python.\"\"\"\n",
    "    response = requests.get(f\"https://dog.ceo/api/breed/{breed.lower()}/images/random\")\n",
    "\n",
    "    if response:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318dbbe8-2269-4ac1-94eb-4ea3889b11d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the retriever tool to our toolset\n",
    "tools_list.append(get_dog_image)\n",
    "\n",
    "# Construct the Tools agent and also the executor\n",
    "llm_agent = initialize_agent(\n",
    "    tools_list, \n",
    "    llm, \n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, #SELF_ASK_WITH_SEARCH,# CONVERSATIONAL_REACT_DESCRIPTION, # ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True,\n",
    "    max_iteration=4,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f632e0-2126-40cf-a208-493acee5ce2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_output = llm_agent.invoke({\"input\": \"give me a labrador image\"})\n",
    "chain_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1aa193-4580-42a2-ab55-95147d7534b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display the dog image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5be21-79fb-4d08-86d5-0e531827e290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if chain_output:\n",
    "    output_str = chain_output[\"output\"]\n",
    "    url_pattern = r'(https?://[^\\s]+)'\n",
    "    url = re.findall(url_pattern, output_str)[0]\n",
    "    print(url)\n",
    "else:\n",
    "    raise TypeError(\"Output cannot be of NoneType\")\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Open the image from the response content\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    # Display the image in the notebook\n",
    "    display(img)\n",
    "else:\n",
    "    print(\"Failed to retrieve the image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daaebf8-befc-4361-a3ac-a751f9eae4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32338171-04a5-4795-8da1-1964cb00d8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3c566-29e9-4c8b-9754-a782d3a7ecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d600f2e-f1bf-4bd7-aa67-6b0263e10008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
